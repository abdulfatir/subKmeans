{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import matmul as MM\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "import skcuda.linalg as LA\n",
    "import skcuda\n",
    "import time\n",
    "import pycuda.driver as drv\n",
    "LA.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name='seeds'):\n",
    "    if name == 'seeds':\n",
    "        with open('datasets/seeds_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.split()\n",
    "                y = x[-1]\n",
    "                x = x[:-1]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            return X, Y\n",
    "    if name == 'wine':\n",
    "         with open('datasets/wine_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            return X, Y  \n",
    "        \n",
    "    if name == 'soy':\n",
    "        with open('datasets/soybean_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[-1]\n",
    "                x = x[:-1]\n",
    "                X.append(x)\n",
    "                Y.append(int(y[-1]) - 1)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            return X, Y  \n",
    "    if name == 'hand':\n",
    "        with open('datasets/handjob_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            Y = Y if np.min(Y) == 0 else Y-1\n",
    "            return X, Y  \n",
    "    if name == 'olive':\n",
    "        with open('datasets/olive_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            Y = Y if np.min(Y) == 0 else Y-1\n",
    "            return X, Y\n",
    "    if name == 'symbol':\n",
    "        with open('datasets/symbol_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            Y = Y if np.min(Y) == 0 else Y-1\n",
    "            return X, Y  \n",
    "    if name == 'plane':\n",
    "        with open('datasets/plane_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "            X = np.array(X, dtype=np.float)\n",
    "            Y = np.array(Y, dtype=np.uint8)\n",
    "            Y = Y if np.min(Y) == 0 else Y-1\n",
    "            return X, Y  \n",
    "    if name == 'mnist':\n",
    "        with open('datasets/mnist_dataset.txt') as ds:\n",
    "            lines = ds.readlines()\n",
    "            X = []\n",
    "            Y = []\n",
    "            for line in lines:\n",
    "                x = line.strip().split(',')\n",
    "                y = x[0]\n",
    "                x = x[1:]\n",
    "                X.append(x)\n",
    "                Y.append(int(float(y)))\n",
    "            X = np.asarray(X, dtype=np.float)\n",
    "            Y = np.asarray(Y, dtype=np.uint8)\n",
    "            Y = Y if np.min(Y) == 0 else Y-1\n",
    "            return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(X):\n",
    "    n, d = X.shape\n",
    "    for i in range(d):\n",
    "        mu = np.mean(X[:, i])\n",
    "        std = np.std(X[:, i]) + 1e-10\n",
    "        X[:, i] = (X[:, i] - mu)/std\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_V(d):\n",
    "#     V_cpu = np.random.uniform(0, 1, [d, d]).astype(np.float32)\n",
    "#     V_gpu = gpuarray.to_gpu(V_cpu)\n",
    "#     start_ortho = time.time()\n",
    "#     Q,R = np.linalg.qr(V_cpu, mode='reduced')\n",
    "#     end_ortho = time.time()\n",
    "#     Q_gpu = gpuarray.to_gpu(Q)\n",
    "#     print(\"orthonormal time: \", (end_ortho-start_ortho))\n",
    "#     return Q_gpu\n",
    "\n",
    "def random_V(d):\n",
    "    V_cpu = np.random.uniform(0, 1, [d, d]).astype(np.float32)\n",
    "    V_gpu = gpuarray.to_gpu(V_cpu)\n",
    "    \n",
    "    start_ortho = drv.Event()\n",
    "    end_ortho = drv.Event()\n",
    "    \n",
    "    start_ortho.record()\n",
    "#     start_ortho = time.time()\n",
    "    Q_gpu, R_gpu = LA.qr(V_gpu, mode='reduced',lib='cusolver')\n",
    "#     end_ortho = time.time()\n",
    "#     print(\"orthonormal time: \", (end_ortho-start_ortho))\n",
    "    \n",
    "    end_ortho.record()\n",
    "    end_ortho.synchronize()\n",
    "    secs = start_ortho.time_till(end_ortho)*1e-3\n",
    "#     print(\"Orthonormal time gpu: \",secs)\n",
    "    QR_time = secs\n",
    "    return Q_gpu, QR_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrices(d, m):\n",
    "    Pc = np.zeros([d, m], dtype=np.uint8)\n",
    "    Pc[:m, :m] = np.eye(m, dtype=np.uint8)\n",
    "    Pc = Pc.astype(np.float32)\n",
    "    Pc_gpu = gpuarray.to_gpu(Pc)\n",
    "    return Pc_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "  #include <stdio.h>\n",
    "  #include <math.h>\n",
    "\n",
    "  __global__ void matmul(float *a, float *b, float *c, int *a_shape, int *b_shape)\n",
    "  {\n",
    "      if((blockDim.y * blockIdx.y + threadIdx.y) < a_shape[0] && (blockDim.x * blockIdx.x + threadIdx.x) < b_shape[1])\n",
    "      {\n",
    "        int aMin = (blockDim.y * blockIdx.y + threadIdx.y) * a_shape[1]; \n",
    "        int aMax = (blockDim.y * blockIdx.y + threadIdx.y + 1) *  a_shape[1]; \n",
    "        int aStep = 1;\n",
    "        int bMin = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        int bMax = blockDim.x * blockIdx.x + threadIdx.x + b_shape[0]*b_shape[1];\n",
    "        int bStep = b_shape[1];\n",
    "        float temp = 0;\n",
    "        for(int ai=aMin, bi = bMin; ai < aMax && bi < bMax; ai += aStep, bi += bStep)\n",
    "        {\n",
    "                temp += a[ai] * b[bi];\n",
    "        }\n",
    "        int a_index = (blockDim.y * blockIdx.y + threadIdx.y) * b_shape[1];\n",
    "        c[a_index+bMin] = temp;\n",
    "    } \n",
    "  }\n",
    "  __global__ void transpose(float *a, float *a_T, int *a_shape) \n",
    "  {\n",
    "      int elem_idx = (blockDim.y * blockIdx.y + threadIdx.y) * a_shape[1] +  blockDim.x * blockIdx.x + threadIdx.x;\n",
    "      if (elem_idx < a_shape[0]*a_shape[1]) \n",
    "          {\n",
    "              int a_t_1 = a_shape[0];\n",
    "              int elem_tr_idx =  (blockDim.x * blockIdx.x + threadIdx.x) * a_t_1 +  blockDim.y * blockIdx.y + threadIdx.y;\n",
    "              a_T[elem_tr_idx] = a[elem_idx];\n",
    "          }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  __global__ void row_mean(float *a, float *mean, int *a_shape)\n",
    "  {\n",
    "  //Returns a column\n",
    "      int row_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (row_num < a_shape[0])\n",
    "      {\n",
    "          int start_idx = row_num*a_shape[1];\n",
    "          int end_idx = start_idx + a_shape[1];\n",
    "          float sum = 0;\n",
    "          for (int i = start_idx; i< end_idx; i++) \n",
    "          {\n",
    "              sum += a[i];\n",
    "          }\n",
    "          mean[row_num] = sum/a_shape[1];\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  __global__ void column_mean(float *a, float *mean, int *a_shape)\n",
    "  {\n",
    "  //Returns a row\n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (col_num < a_shape[1])\n",
    "      {\n",
    "          int start_idx = col_num;\n",
    "          int end_idx = start_idx + a_shape[1]*a_shape[0];\n",
    "          float sum = 0;\n",
    "          for (int i = start_idx; i< end_idx; i+= a_shape[1]) \n",
    "          {\n",
    "              sum += a[i];\n",
    "          }\n",
    "          mean[col_num] = sum/a_shape[0];\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  __global__ void min_row(float *a, int *a_shape, float *min_row, int *arg_min)\n",
    "  {\n",
    "    //Returns a column for min_row and argmin \n",
    "      int row_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (row_num < a_shape[0])\n",
    "      {\n",
    "          int start_idx = row_num*a_shape[1];\n",
    "          int end_idx = start_idx + a_shape[1];\n",
    "          min_row[row_num] = a[start_idx];\n",
    "          arg_min[row_num] = 0;\n",
    "          for (int col = start_idx+1, index=1; col< end_idx, index < a_shape[1]; col++, index ++) \n",
    "          {\n",
    "              if (a[col] < min_row[row_num])\n",
    "              {\n",
    "                  min_row[row_num] = a[col];\n",
    "                  arg_min[row_num] = index;\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  __global__ void sum_axis3(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[0] && col_num < a_shape[1])\n",
    "      {\n",
    "          int start_idx =(row_num*a_shape[1] + col_num)*a_shape[2];\n",
    "          int end_idx = start_idx + a_shape[2];\n",
    "          int step = 1;\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[1] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "    __global__ void sum_axis2(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[0] && col_num < a_shape[2])\n",
    "      {\n",
    "          int start_idx =row_num*a_shape[1]*a_shape[2] + col_num;\n",
    "          int end_idx = start_idx + a_shape[2]*a_shape[1];\n",
    "          int step = a_shape[2];\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[2] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "    __global__ void sum_axis1(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[1] && col_num < a_shape[2])\n",
    "      {\n",
    "          int start_idx =(row_num)*a_shape[2] + col_num;\n",
    "          int end_idx = start_idx + a_shape[2]*a_shape[1]*a_shape[0];\n",
    "          int step = a_shape[2]*a_shape[1];\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[2] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  __global__ void argmin_mu_diff(float *data, float *mu, int *data_shape, int *mu_shape, int *arg_min)\n",
    "  {\n",
    "      \n",
    "      int data_id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "      if (data_id < data_shape[0] )\n",
    "      {\n",
    "          int startIdx = (blockDim.x * blockIdx.x + threadIdx.x)*data_shape[1];\n",
    "          float min_diff = INT_MAX;\n",
    "          float arg_min_diff = -1;\n",
    "          for (int i=0; i<mu_shape[0]; i++) \n",
    "          {\n",
    "              float diff = 0;\n",
    "              for (int dim = 0; dim < mu_shape[1]; dim ++)\n",
    "              {\n",
    "                  diff += (data[startIdx+dim] - mu[i*mu_shape[1] + dim])*(data[startIdx+dim] - mu[i*mu_shape[1] + dim]);\n",
    "              }\n",
    "              if (diff < min_diff)\n",
    "              {\n",
    "                  min_diff = diff;\n",
    "                  arg_min_diff = i;\n",
    "              }\n",
    "          }\n",
    "          arg_min[data_id] = arg_min_diff;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  \n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_kmeans(X, k, KERNEL=False):\n",
    "    \n",
    "    \n",
    "    start = drv.Event()\n",
    "    end = drv.Event()\n",
    "    \n",
    "    \n",
    "    n, d = X.shape\n",
    "    V_gpu, QR_time = random_V(d)\n",
    "    \n",
    "    m = d/2\n",
    "    \n",
    "    # Algorithm line 5\n",
    "    #################################################################################\n",
    "    start = drv.Event()\n",
    "    end = drv.Event()\n",
    "    start.record()\n",
    "    start.synchronize()\n",
    "    \n",
    "    X_gpu =  gpuarray.to_gpu(X) # n, d\n",
    "    \n",
    "    if KERNEL == True:\n",
    "        \n",
    "        func = mod.get_function(\"column_mean\")\n",
    "        BLOCK_DIMX = 1024\n",
    "        GRID_DIMX = int(np.ceil(X_gpu.shape[1]/float(BLOCK_DIMX)))\n",
    "        SHAPE_A_gpu = gpuarray.to_gpu(np.asarray([n,d]).astype(np.uint32))\n",
    "        mu_D_gpu = gpuarray.empty((1,d), dtype=np.float32)\n",
    "        func(X_gpu, mu_D_gpu, SHAPE_A_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        mu_D_gpu = skcuda.misc.mean(X_gpu, axis=0, keepdims=True) # 1, d\n",
    "    \n",
    "    end.record()\n",
    "    end.synchronize()\n",
    "#     print(\"Mu_d gpu: \",start.time_till(end)*1e-3)\n",
    "    mu_d_time = start.time_till(end)*1e-3\n",
    "    #################################################################################\n",
    "    \n",
    "    # Algorithm line 6\n",
    "    #################################################################################\n",
    "    start.record()\n",
    "    start.synchronize()\n",
    "    \n",
    "    sub_gpu = skcuda.misc.subtract(X_gpu, mu_D_gpu) # n,d\n",
    "    \n",
    "    if KERNEL == True:\n",
    "        \n",
    "        sub_gpu_T = LA.transpose(sub_gpu)\n",
    "        S_D_gpu = gpuarray.empty((d,d), dtype=np.float32)\n",
    "        \n",
    "        func = mod.get_function(\"matmul\")\n",
    "        BLOCK_DIMX = 32\n",
    "        BLOCK_DIMY = 32\n",
    "        SHAPE_A_gpu = gpuarray.to_gpu(np.asarray([d,n]).astype(np.uint32))\n",
    "        SHAPE_B_gpu = gpuarray.to_gpu(np.asarray([n,d]).astype(np.uint32))\n",
    "        GRID_DIMX = int(np.ceil(d/float(BLOCK_DIMX)))\n",
    "        GRID_DIMY = int(np.ceil(d/float(BLOCK_DIMY)))\n",
    "        \n",
    "        func(sub_gpu_T, sub_gpu, S_D_gpu, SHAPE_A_gpu,SHAPE_B_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))\n",
    "    \n",
    "    else:\n",
    "        S_D_gpu = LA.dot(sub_gpu,sub_gpu,transa='T') # d,d\n",
    "    \n",
    "    end.record()\n",
    "    end.synchronize()\n",
    "#     print(\"S_d gpu: \",start.time_till(end)*1e-3)\n",
    "    S_d_time = start.time_till(end)*1e-3\n",
    "    #################################################################################\n",
    "    \n",
    "    \n",
    "    mu_is_gpu = gpuarray.to_gpu(X[np.random.choice(n, k)]) # k, d\n",
    "    itr = 1\n",
    "    assignment_unchanged = 0    \n",
    "    \n",
    "    \n",
    "    argmin_times = []\n",
    "    mu_Si_times = []\n",
    "    eig_times = []\n",
    "    \n",
    "    while True:\n",
    "#         print(itr)\n",
    "        \n",
    "        Pc_gpu = projection_matrices(d, m) # d, m\n",
    "        \n",
    "        # Algorithm line 11\n",
    "        #################################################################################\n",
    "        start.record()\n",
    "        start.synchronize()\n",
    "        \n",
    "        PcV_gpu = LA.dot(Pc_gpu,V_gpu,transa='T',transb='T') # m,d\n",
    "        PcVmu_is_gpu = gpuarray.empty((k,m), dtype = np.float32) # k, m\n",
    "        \n",
    "        for i in xrange(k):\n",
    "            PcVmu_is_gpu[i] = LA.dot(PcV_gpu,mu_is_gpu[i][:,None]).ravel() # m,d * d,1 = m\n",
    "        \n",
    "        \n",
    "        global_temp = LA.dot(X_gpu, PcV_gpu, transb='T') # n,d * d,m => n,m\n",
    "        \n",
    "        if itr %2 ==0:\n",
    "            C_old = C_gpu.get()\n",
    "        \n",
    "        \n",
    "        if KERNEL == True:\n",
    "            \n",
    "            C_gpu = gpuarray.empty((n), dtype = np.uint32) # n    \n",
    "            \n",
    "\n",
    "            func = mod.get_function(\"argmin_mu_diff\")\n",
    "            BLOCK_DIMX = 1024\n",
    "            GRID_DIMX = int(np.ceil(global_temp.shape[0]/float(BLOCK_DIMX)))\n",
    "            SHAPE_A_gpu = gpuarray.to_gpu(np.asarray([n,m]).astype(np.uint32))\n",
    "            SHAPE_MU_gpu = gpuarray.to_gpu(np.asarray([k,m]).astype(np.uint32))\n",
    "\n",
    "            func(global_temp, PcVmu_is_gpu, SHAPE_A_gpu,SHAPE_MU_gpu, C_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            X_transformed_gpu = gpuarray.empty((n,k,m),dtype=np.float32) # n, k, m\n",
    "            for i in xrange(n):\n",
    "                temp = global_temp[i] # 1,m\n",
    "                X_transformed_gpu[i] =skcuda.misc.subtract(PcVmu_is_gpu ,temp) # k, m \n",
    "\n",
    "                \n",
    "            X_transformed_squared_gpu = LA.multiply(X_transformed_gpu,X_transformed_gpu) # n, k, m\n",
    "            X_transformed_squared_gpu = X_transformed_squared_gpu.reshape((n*k,m))\n",
    "            X_transformed_sum_gpu = skcuda.misc.sum(X_transformed_squared_gpu, axis=-1, keepdims=True)\n",
    "            X_transformed_sum_gpu = X_transformed_sum_gpu.reshape((n,k))\n",
    "            C_gpu = skcuda.misc.argmin(X_transformed_sum_gpu, axis=1) # n (clusters assigned)\n",
    "        \n",
    "        \n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "#         print(\"Argmin gpu: \",start.time_till(end)*1e-3)\n",
    "        argmin_times.append(start.time_till(end)*1e-3)\n",
    "        #################################################################################    \n",
    "        \n",
    "        if itr % 2 == 0:\n",
    "            Cnew = C_gpu.get()\n",
    "            points_changed = np.sum(1 - np.equal(C_old, Cnew).astype(np.uint8))\n",
    "            if points_changed == 0:\n",
    "                assignment_unchanged += 1\n",
    "            if assignment_unchanged >= 2:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        # Algorithm line 14\n",
    "        #################################################################################\n",
    "        start.record()\n",
    "        start.synchronize()\n",
    "        \n",
    "        C = C_gpu.get()\n",
    "        counts = {i:0 for i in range(k)}\n",
    "        \n",
    "        \n",
    "        if KERNEL==True:\n",
    "            mu_is_gpu = gpuarray.empty((k,d), dtype=np.float32) # k, d\n",
    "            \n",
    "            for i in xrange(n): \n",
    "                C_id = np.int(C[i])\n",
    "                counts[C_id] += 1\n",
    "            maxv = np.max(counts.values())\n",
    "            storage = np.zeros((k, np.int(maxv), d)).astype(np.float32)\n",
    "            \n",
    "            counter = np.zeros(k, dtype= np.uint32) # k\n",
    "            for i in range(n):\n",
    "                C_id = np.int(C[i])\n",
    "                storage[C_id, np.int(counter[C_id]),:] = X[i].ravel()\n",
    "                counter[C_id]+=1\n",
    "\n",
    "            storage_gpu = gpuarray.to_gpu(storage) # k, maxv, d\n",
    "            \n",
    "            func = mod.get_function(\"sum_axis2\")\n",
    "            BLOCK_DIMX = 32\n",
    "            BLOCK_DIMY = 32\n",
    "            GRID_DIMX = int(np.ceil(storage_gpu.shape[2]/float(BLOCK_DIMX)))\n",
    "            GRID_DIMY = int(np.ceil(storage_gpu.shape[0]/float(BLOCK_DIMY)))\n",
    "            \n",
    "            SHAPE_A_gpu = gpuarray.to_gpu(np.asarray([k, np.int(maxv), d]).astype(np.uint32))\n",
    "            \n",
    "            func(storage_gpu, SHAPE_A_gpu, mu_is_gpu , block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))\n",
    "            \n",
    "            counter_gpu = gpuarray.to_gpu(counter)[:,None]\n",
    "            \n",
    "            mu_is_gpu = skcuda.misc.divide(mu_is_gpu, counter_gpu.astype(np.float32)) # k , d\n",
    "        else:\n",
    "            mu_is = np.zeros( (k,d)).astype(np.float32) #k,d\n",
    "            for i in xrange(n): \n",
    "                C_id = np.int(C[i])\n",
    "                mu_is[C_id] += X[i]\n",
    "                counts[C_id] += 1\n",
    "\n",
    "            mu_is = np.array([mu_is[i]/counts[i] for i in range(k)])\n",
    "            mu_is_gpu = gpuarray.to_gpu(mu_is) # k, d\n",
    "        \n",
    "#         end.record()\n",
    "#         end.synchronize()\n",
    "#         print(\"New_mu gpu: \",start.time_till(end)*1e-3)\n",
    "        #################################################################################    \n",
    "            \n",
    "        \n",
    "        # Algorithm line 15\n",
    "        #################################################################################\n",
    "#         start.record()\n",
    "#         start.synchronize()\n",
    "        \n",
    "        if KERNEL == True:\n",
    "            S_is_gpu = gpuarray.zeros( (k, d, d), dtype= np.float32) #k,d,d\n",
    "            \n",
    "            for i in range(k):\n",
    "                storage_gpu[i] = skcuda.misc.subtract(storage_gpu[i],mu_is_gpu[i])\n",
    "                curr_cluster_points = storage_gpu[i,:np.int(counter[i]),:] # |k|,d\n",
    "                S_is_gpu[i]=  LA.dot(curr_cluster_points,curr_cluster_points,transa='T') # d,|k| * |k|,d = d,\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            S_is_gpu = gpuarray.zeros( (k, d, d), dtype= np.float32) #k,d,d\n",
    "\n",
    "            maxv = np.max(counts.values())\n",
    "            storage = np.empty((k, np.int(maxv), d)).astype(np.float32)\n",
    "            counter = np.zeros(k, dtype= np.uint32) # k\n",
    "\n",
    "            for i in range(n):\n",
    "                C_id = np.int(C[i])\n",
    "                X_minus_mu_isi = (X[i] - mu_is[C_id])[:,None] # d, 1\n",
    "                storage[C_id, np.int(counter[C_id]),:] = X_minus_mu_isi.ravel()\n",
    "                counter[C_id]+=1\n",
    "\n",
    "            storage_gpu = gpuarray.to_gpu(storage)\n",
    "            for i in range(k):\n",
    "                curr_cluster_points = storage_gpu[i,:np.int(counter[i]),:] # |k|,d\n",
    "                S_is_gpu[i]=  LA.dot(curr_cluster_points,curr_cluster_points,transa='T')      # d,|k| * |k|,d = d,d\n",
    "\n",
    "\n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "#         print(\"New_mu and New_s_i gpu: \",start.time_till(end)*1e-3)\n",
    "        mu_Si_times.append(start.time_till(end)*1e-3)\n",
    "        #################################################################################    \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Algorithm line 16\n",
    "        #################################################################################\n",
    "        start.record()\n",
    "        start.synchronize()\n",
    "        \n",
    "        \n",
    "        S_is_sum_gpu = S_is_gpu.reshape((k,d*d))\n",
    "        S_is_sum_gpu = skcuda.misc.sum(S_is_sum_gpu, axis=0, keepdims=True)\n",
    "        S_is_sum_gpu = S_is_sum_gpu.reshape((d,d))\n",
    "\n",
    "        S_is_diff_gpu = skcuda.misc.subtract(S_is_sum_gpu, S_D_gpu)\n",
    "                \n",
    "        vr_gpu, w_gpu = LA.eig(S_is_diff_gpu, 'N', 'V', lib='cusolver')\n",
    "        \n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "#         print(\"Eigen_decomp gpu: \",start.time_till(end)*1e-3)\n",
    "        eig_times.append(start.time_till(end)*1e-3)\n",
    "        #################################################################################    \n",
    "        \n",
    "        \n",
    "        \n",
    "        w = w_gpu.get()\n",
    "        w_idx = np.argsort(w)\n",
    "        \n",
    "        for i in xrange(d):\n",
    "            V_gpu[i] = vr_gpu[w_idx[i]]\n",
    "        V_gpu = LA.transpose(V_gpu)\n",
    "            \n",
    "\n",
    "        maxVal = min(w)\n",
    "        m = np.sum([1 for i in w if i/maxVal > 1e-3])\n",
    "        m = max(1, m)\n",
    "        \n",
    "        itr+=1\n",
    "        \n",
    "        \n",
    "    return C_gpu.get(), V_gpu.get(), m, QR_time, mu_d_time, S_d_time, argmin_times, mu_Si_times, eig_times, itr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times(QR_time, mu_d_time, S_d_time, argmin_times, mu_Si_times, eig_times, overall_all, itr, m, nmi):\n",
    "    \n",
    "    print('itr: ', np.mean(itr))\n",
    "    max_nmi_idx = np.argmax(nmi)\n",
    "    print('m: ', m[max_nmi_idx])\n",
    "    print('nmi: ', nmi[max_nmi_idx])\n",
    "    \n",
    "    print(\"Orthogonal time gpu: \", np.mean(QR_time))\n",
    "    print(\"mu_d_time gpu: \", np.mean(mu_d_time))\n",
    "    print(\"S_d_time gpu:\", np.mean(S_d_time))\n",
    "    \n",
    "    argmin_times = np.asarray(argmin_times)\n",
    "    mu_Si_times = np.asarray(mu_Si_times)\n",
    "    eig_times = np.asarray(eig_times)\n",
    "    \n",
    "    print(\"Argim_time_avg gpu: \", np.mean(argmin_times))\n",
    "    print(\"Argim_time_std gpu: \", np.std(argmin_times))\n",
    "    print(\"mu_Si_time_avg gpu: \", np.mean(mu_Si_times))\n",
    "    print(\"mu_Si_time_std gpu: \", np.std(mu_Si_times))\n",
    "    print(\"eig_times_avg gpu: \", np.mean(eig_times))\n",
    "    print(\"eig_times_std gpu: \", np.std(eig_times))\n",
    "\n",
    "    print(\"Total time: \", np.mean(overall_all))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_dataset('mnist')\n",
    "X = X.astype(np.float32)\n",
    "X = normalize_dataset(X)\n",
    "\n",
    "l_QR_time, l_mu_d_time, l_S_d_time, l_argmin_times, l_mu_Si_times, l_eig_times, l_overall_time = [],[],[],[],[],[], []\n",
    "l_itr = []\n",
    "l_nmi, l_m = [], []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    # Overall time\n",
    "    #################################################################################\n",
    "    start_overall = drv.Event()\n",
    "    end_overall = drv.Event()\n",
    "    start_overall.record()\n",
    "    start_overall.synchronize()\n",
    "    \n",
    "    C, V,  m, QR_time, mu_d_time, S_d_time, argmin_times, mu_Si_times, eig_times, \\\n",
    "    itr = sub_kmeans(X, 10, KERNEL=True)\n",
    "    \n",
    "    end_overall.record()\n",
    "    end_overall.synchronize()\n",
    "    overall_time = start_overall.time_till(end_overall)*1e-3\n",
    "    #################################################################################    \n",
    "    \n",
    "    l_QR_time.append(QR_time)\n",
    "    l_mu_d_time.append(mu_d_time)\n",
    "    l_S_d_time.append(S_d_time)\n",
    "    l_argmin_times+=argmin_times\n",
    "    l_mu_Si_times+=mu_Si_times\n",
    "    l_eig_times+=eig_times\n",
    "    l_overall_time.append(overall_time)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Pc = projection_matrices(X.shape[1], m)\n",
    "    trans = V.T\n",
    "    X_rotated = MM(trans[None, :, :], np.transpose(X[:, None, :], [0, 2, 1]))\n",
    "    X_rotated = X_rotated.squeeze(-1).T\n",
    "    acc = nmi(Y, C)\n",
    "    l_nmi.append(acc)\n",
    "    l_m.append(m)\n",
    "    l_itr.append(itr)    \n",
    "#     plt.scatter(X_rotated[0], X_rotated[1], c=C)\n",
    "#     plt.show()\n",
    "\n",
    "times(l_QR_time, l_mu_d_time, l_S_d_time, l_argmin_times, l_mu_Si_times, l_eig_times, l_overall_time, l_itr, l_m, l_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
