{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:183: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu(81): warning: expression has no effect\n",
      "\n",
      "kernel.cu(81): warning: expression has no effect\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "  #include <stdio.h>\n",
    "  #include <math.h>\n",
    "\n",
    "  __global__ void matmul(float *a, float *b, float *c, int *a_shape, int *b_shape)\n",
    "  {\n",
    "      if((blockDim.y * blockIdx.y + threadIdx.y) < a_shape[0] && (blockDim.x * blockIdx.x + threadIdx.x) < b_shape[1])\n",
    "      {\n",
    "        int aMin = (blockDim.y * blockIdx.y + threadIdx.y) * a_shape[1]; \n",
    "        int aMax = (blockDim.y * blockIdx.y + threadIdx.y + 1) *  a_shape[1]; \n",
    "        int aStep = 1;\n",
    "        int bMin = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "        int bMax = blockDim.x * blockIdx.x + threadIdx.x + b_shape[0]*b_shape[1];\n",
    "        int bStep = b_shape[1];\n",
    "        float temp = 0;\n",
    "        for(int ai=aMin, bi = bMin; ai < aMax && bi < bMax; ai += aStep, bi += bStep)\n",
    "        {\n",
    "                temp += a[ai] * b[bi];\n",
    "        }\n",
    "        int a_index = (blockDim.y * blockIdx.y + threadIdx.y) * b_shape[1];\n",
    "        c[a_index+bMin] = temp;\n",
    "    } \n",
    "  }\n",
    "  __global__ void transpose(float *a, float *a_T, int *a_shape) \n",
    "  {\n",
    "      int elem_idx = (blockDim.y * blockIdx.y + threadIdx.y) * a_shape[1] +  blockDim.x * blockIdx.x + threadIdx.x;\n",
    "      if (elem_idx < a_shape[0]*a_shape[1]) \n",
    "          {\n",
    "              int a_t_1 = a_shape[0];\n",
    "              int elem_tr_idx =  (blockDim.x * blockIdx.x + threadIdx.x) * a_t_1 +  blockDim.y * blockIdx.y + threadIdx.y;\n",
    "              a_T[elem_tr_idx] = a[elem_idx];\n",
    "          }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  __global__ void row_mean(float *a, float *mean, int *a_shape)\n",
    "  {\n",
    "  //Returns a column\n",
    "      int row_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (row_num < a_shape[0])\n",
    "      {\n",
    "          int start_idx = row_num*a_shape[1];\n",
    "          int end_idx = start_idx + a_shape[1];\n",
    "          float sum = 0;\n",
    "          for (int i = start_idx; i< end_idx; i++) \n",
    "          {\n",
    "              sum += a[i];\n",
    "          }\n",
    "          mean[row_num] = sum/a_shape[1];\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  __global__ void column_mean(float *a, float *mean, int *a_shape)\n",
    "  {\n",
    "  //Returns a row\n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (col_num < a_shape[1])\n",
    "      {\n",
    "          int start_idx = col_num;\n",
    "          int end_idx = start_idx + a_shape[1]*a_shape[0];\n",
    "          float sum = 0;\n",
    "          for (int i = start_idx; i< end_idx; i+= a_shape[1]) \n",
    "          {\n",
    "              sum += a[i];\n",
    "          }\n",
    "          mean[col_num] = sum/a_shape[0];\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  __global__ void min_row(float *a, int *a_shape, float *min_row, int *arg_min)\n",
    "  {\n",
    "    //Returns a column for min_row and argmin \n",
    "      int row_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      if (row_num < a_shape[0])\n",
    "      {\n",
    "          int start_idx = row_num*a_shape[1];\n",
    "          int end_idx = start_idx + a_shape[1];\n",
    "          min_row[row_num] = a[start_idx];\n",
    "          arg_min[row_num] = 0;\n",
    "          for (int col = start_idx+1, index=1; col< end_idx, index < a_shape[1]; col++, index ++) \n",
    "          {\n",
    "              if (a[col] < min_row[row_num])\n",
    "              {\n",
    "                  min_row[row_num] = a[col];\n",
    "                  arg_min[row_num] = index;\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  __global__ void sum_axis3(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[0] && col_num < a_shape[1])\n",
    "      {\n",
    "          int start_idx =(row_num*a_shape[1] + col_num)*a_shape[2];\n",
    "          int end_idx = start_idx + a_shape[2];\n",
    "          int step = 1;\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[1] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "    __global__ void sum_axis2(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[0] && col_num < a_shape[2])\n",
    "      {\n",
    "          int start_idx =row_num*a_shape[1]*a_shape[2] + col_num;\n",
    "          int end_idx = start_idx + a_shape[2]*a_shape[1];\n",
    "          int step = a_shape[2];\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[2] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "    __global__ void sum_axis1(float *a, int *a_shape, float *result)\n",
    "  {\n",
    "      //a[i][j][k] = k+a_shape[2]*j + a_shape[2]*a_shape[1]*i\n",
    "      \n",
    "      int col_num = (blockDim.x * blockIdx.x + threadIdx.x);\n",
    "      int row_num = (blockDim.y * blockIdx.y + threadIdx.y);\n",
    "      if (row_num < a_shape[1] && col_num < a_shape[2])\n",
    "      {\n",
    "          int start_idx =(row_num)*a_shape[2] + col_num;\n",
    "          int end_idx = start_idx + a_shape[2]*a_shape[1]*a_shape[0];\n",
    "          int step = a_shape[2]*a_shape[1];\n",
    "          float temp = 0;\n",
    "          for (int idx = start_idx; idx < end_idx; idx+= step) \n",
    "          {\n",
    "              temp += a[idx];\n",
    "          }\n",
    "          result[row_num*a_shape[2] + col_num] = temp;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "      __global__ void argmin_mu_diff(float *data, float *mu, int *data_shape, int *mu_shape, int *arg_min)\n",
    "  {\n",
    "      \n",
    "      int data_id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "      if (data_id < data_shape[0] )\n",
    "      {\n",
    "          int startIdx = (blockDim.x * blockIdx.x + threadIdx.x)*data_shape[1];\n",
    "          float min_diff = INT_MAX;\n",
    "          float arg_min_diff = -1;\n",
    "          for (int i=0; i<mu_shape[0]; i++) \n",
    "          {\n",
    "              float diff = 0;\n",
    "              for (int dim = 0; dim < mu_shape[1]; dim ++)\n",
    "              {\n",
    "                  diff += (data[startIdx+dim] - mu[i*mu_shape[1] + dim])*(data[startIdx+dim] - mu[i*mu_shape[1] + dim]);\n",
    "              }\n",
    "              if (diff < min_diff)\n",
    "              {\n",
    "                  min_diff = diff;\n",
    "                  arg_min_diff = i;\n",
    "              }\n",
    "          }\n",
    "          arg_min[data_id] = arg_min_diff;\n",
    "      }\n",
    "  \n",
    "  }\n",
    "  \n",
    "  \n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10549, 8982).astype(np.float32)\n",
    "b = np.random.randn(8982, 10549).astype(np.float32)\n",
    "c = np.zeros([a.shape[0], b.shape[1]]).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)\n",
    "SHAPE_B = np.array(b.shape).astype(np.uint32)\n",
    "print(SHAPE_A, SHAPE_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)\n",
    "cuda.memcpy_htod(c_gpu, c)\n",
    "\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)\n",
    "SHAPE_B_gpu = cuda.mem_alloc(SHAPE_B.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_B_gpu, SHAPE_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"matmul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCK_DIMX = 32\n",
    "BLOCK_DIMY = 32\n",
    "GRID_DIMX = int(np.ceil(b.shape[1]/float(BLOCK_DIMX)))\n",
    "GRID_DIMY = int(np.ceil(a.shape[0]/float(BLOCK_DIMY)))\n",
    "\n",
    "print (GRID_DIMX, GRID_DIMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, b_gpu, c_gpu, SHAPE_A_gpu, SHAPE_B_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(c)\n",
    "cuda.memcpy_dtoh(results, c_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.matmul(a, b), results, atol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRANSPOSE##\n",
    "a = np.random.randn(10549, 8982).astype(np.float32)\n",
    "a_T = np.zeros(list(reversed(a.shape))).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "a_T_gpu = cuda.mem_alloc(a_T.nbytes)\n",
    "cuda.memcpy_htod(a_T_gpu, a_T)\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"transpose\")\n",
    "BLOCK_DIMX = 32\n",
    "BLOCK_DIMY = 32\n",
    "GRID_DIMX = int(np.ceil(a.shape[1]/float(BLOCK_DIMX)))\n",
    "GRID_DIMY = int(np.ceil(a.shape[0]/float(BLOCK_DIMY)))\n",
    "print (GRID_DIMX, GRID_DIMY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, a_T_gpu, SHAPE_A_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(a_T)\n",
    "cuda.memcpy_dtoh(results, a_T_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.transpose(a), results, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.transpose(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROW MEAN ##\n",
    "a = np.random.randn(10549, 8982).astype(np.float32)\n",
    "mean_a = np.zeros([a.shape[0]]).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "mean_a_gpu = cuda.mem_alloc(mean_a.nbytes)\n",
    "cuda.memcpy_htod(mean_a_gpu, mean_a)\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"row_mean\")\n",
    "BLOCK_DIMX = 1024\n",
    "GRID_DIMX = int(np.ceil(a.shape[1]*a.shape[0]/float(BLOCK_DIMX)))\n",
    "print (GRID_DIMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, mean_a_gpu, SHAPE_A_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(mean_a)\n",
    "cuda.memcpy_dtoh(results, mean_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.mean(a, axis=1), results, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.mean(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COLUMN MEAN ##\n",
    "a = np.random.randn(10549, 8982).astype(np.float32)\n",
    "mean_a = np.zeros([a.shape[1]]).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "mean_a_gpu = cuda.mem_alloc(mean_a.nbytes)\n",
    "cuda.memcpy_htod(mean_a_gpu, mean_a)\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"column_mean\")\n",
    "BLOCK_DIMX = 1024\n",
    "GRID_DIMX = int(np.ceil(a.shape[1]*a.shape[0]/float(BLOCK_DIMX)))\n",
    "print (GRID_DIMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, mean_a_gpu, SHAPE_A_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(mean_a)\n",
    "cuda.memcpy_dtoh(results, mean_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.mean(a, axis=0), results, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.mean(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ARGMIN, MIN ##\n",
    "a = np.random.randn(10549, 8982).astype(np.float32)\n",
    "min_a = np.zeros([a.shape[0]]).astype(np.float32)\n",
    "argmin_a = np.zeros([a.shape[0]]).astype(np.uint32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "min_a_gpu = cuda.mem_alloc(min_a.nbytes)\n",
    "cuda.memcpy_htod(min_a_gpu, min_a)\n",
    "argmin_a_gpu = cuda.mem_alloc(argmin_a.nbytes)\n",
    "cuda.memcpy_htod(argmin_a_gpu, argmin_a)\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"min_row\")\n",
    "BLOCK_DIMX = 1024\n",
    "GRID_DIMX = int(np.ceil(a.shape[1]*a.shape[0]/float(BLOCK_DIMX)))\n",
    "print (GRID_DIMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, SHAPE_A_gpu, min_a_gpu, argmin_a_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(min_a)\n",
    "cuda.memcpy_dtoh(results, min_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.min(a, axis=1), results, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.min(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(argmin_a)\n",
    "cuda.memcpy_dtoh(results, argmin_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.argmin(a, axis=1), results, atol=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUM AXIS##\n",
    "a = np.random.randn(1054, 89,45).astype(np.float32)\n",
    "sum3_a = np.zeros([a.shape[0], a.shape[1]]).astype(np.float32)\n",
    "sum2_a = np.zeros([a.shape[0], a.shape[2]]).astype(np.float32)\n",
    "sum1_a = np.zeros([a.shape[1], a.shape[2]]).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "sum3_a_gpu = cuda.mem_alloc(sum3_a.nbytes)\n",
    "cuda.memcpy_htod(sum3_a_gpu, sum3_a)\n",
    "sum2_a_gpu = cuda.mem_alloc(sum2_a.nbytes)\n",
    "cuda.memcpy_htod(sum2_a_gpu, sum2_a)\n",
    "sum1_a_gpu = cuda.mem_alloc(sum1_a.nbytes)\n",
    "cuda.memcpy_htod(sum1_a_gpu, sum1_a)\n",
    "\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"sum_axis3\")\n",
    "BLOCK_DIMX = 32\n",
    "BLOCK_DIMY = 32\n",
    "GRID_DIMX = int(np.ceil(a.shape[1]/float(BLOCK_DIMX)))\n",
    "GRID_DIMY = int(np.ceil(a.shape[0]/float(BLOCK_DIMY)))\n",
    "print (GRID_DIMX, GRID_DIMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, SHAPE_A_gpu, sum3_a_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(sum3_a)\n",
    "cuda.memcpy_dtoh(results, sum3_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.sum(a, axis=2), results, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.sum(a, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"sum_axis2\")\n",
    "BLOCK_DIMX = 32\n",
    "BLOCK_DIMY = 32\n",
    "GRID_DIMX = int(np.ceil(a.shape[2]/float(BLOCK_DIMX)))\n",
    "GRID_DIMY = int(np.ceil(a.shape[0]/float(BLOCK_DIMY)))\n",
    "print (GRID_DIMX, GRID_DIMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, SHAPE_A_gpu, sum2_a_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(sum2_a)\n",
    "cuda.memcpy_dtoh(results, sum2_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.sum(a, axis=1), results, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"sum_axis1\")\n",
    "BLOCK_DIMX = 32\n",
    "BLOCK_DIMY = 32\n",
    "GRID_DIMX = int(np.ceil(a.shape[2]/float(BLOCK_DIMX)))\n",
    "GRID_DIMY = int(np.ceil(a.shape[1]/float(BLOCK_DIMY)))\n",
    "print (GRID_DIMX, GRID_DIMY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "func(a_gpu, SHAPE_A_gpu, sum1_a_gpu, block=(BLOCK_DIMX, BLOCK_DIMY, 1), grid=(GRID_DIMX, GRID_DIMY, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty_like(sum1_a)\n",
    "cuda.memcpy_dtoh(results, sum1_a_gpu)\n",
    "print(results)\n",
    "print(np.allclose(np.sum(a, axis=0), results, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MU_DIFF#\n",
    "a = np.random.randn(1054, 89).astype(np.float32)\n",
    "mu = np.random.randn(25, 89).astype(np.float32)\n",
    "SHAPE_A = np.array(a.shape).astype(np.uint32)\n",
    "SHAPE_MU = np.array(mu.shape).astype(np.uint32)\n",
    "argmin = np.zeros(a.shape[0]).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "mu_gpu = cuda.mem_alloc(mu.nbytes)\n",
    "cuda.memcpy_htod(mu_gpu, mu)\n",
    "\n",
    "SHAPE_A_gpu = cuda.mem_alloc(SHAPE_A.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_A_gpu, SHAPE_A)\n",
    "\n",
    "SHAPE_MU_gpu = cuda.mem_alloc(SHAPE_MU.nbytes)\n",
    "cuda.memcpy_htod(SHAPE_MU_gpu, SHAPE_MU)\n",
    "\n",
    "argmin_gpu = cuda.mem_alloc(argmin.nbytes)\n",
    "cuda.memcpy_htod(argmin_gpu, argmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "func = mod.get_function(\"argmin_mu_diff\")\n",
    "BLOCK_DIMX = 1024\n",
    "GRID_DIMX = int(np.ceil(a.shape[0]/float(BLOCK_DIMX)))\n",
    "print (GRID_DIMX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 µs, sys: 143 µs, total: 443 µs\n",
      "Wall time: 451 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "func(a_gpu, mu_gpu, SHAPE_A_gpu,SHAPE_MU_gpu, argmin_gpu, block=(BLOCK_DIMX, 1, 1), grid=(GRID_DIMX, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 12 ..., 13 12 23]\n"
     ]
    }
   ],
   "source": [
    "results = np.empty_like(argmin)\n",
    "cuda.memcpy_dtoh(results, argmin_gpu)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 8.03 ms, total: 20 ms\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ans = np.argmin(np.sum(np.square(a[:, None, :] - mu[None, :, :]), axis=-1), axis=-1) # n,k,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(ans, results, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
